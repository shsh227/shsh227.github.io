# shsh227.github.io
### Video Demo:
### Description: My final coding project is a globally accessible webpage that displays the most current good news to the viewer. To get it working, I had to code several different files. First of all, there is scrape_news.py. This is a python script that on top imports all necessary libraries such as e.g. selenium. It then adds some chrome options to avoid errors so that the chrome driver can be directed to a website called goodnews.eu. For that, I have also downloaded chromedriver.exe into my project folder. The website called goodnews dynamically uploads good news every few days. My script creates a database called goodnews.db which at the beginning is empty. Then, it starts scanning the general website’s html code for the divisions that define those articles interesting to me (either the top one from the latest date or the older ones beneath) and stores them in a variable. For each, it scans the website’s html and finds the url link of that article. Then, it follows that url to the associated webpage. For each article, it then extracts the publication date, title, summary and image url. The code does this once for the most current date (because the webpage html of that article is slightly different to the ones beneath) and then for all the other articles on the website, filtered by publication date of the current week (meaning articles older than seven days are skipped). If everything is found for an article, the information is stored in the goodnews.db database. For debug reasons, some information (e.g. found title and summary etc) are printed in the process. Next, there is app.py. This script specifically uses Flask to access the database, selects the latest 15 articles and passes them into index.html. In a templates folder, I further specify the index.html. It consists of a head and a body. The head connects to a CSS file, sets the title and assures that the webpage can look aesthetic also on smaller screens (further specified in the CSS file). Additionally, it uses some JavaScript so that only one article is displayed at a time – sliding through the different news like an advertisement slideshow. As soon as the content is loaded, one article is selected as being shown while the others are hidden. After a set amount of time, these configurations switch to the next article. In addition to that, some specifications define that a fullscreen button can be seen and clicked. The screen is then converted to full screen and an exit fullscreen button takes its place, reverting the changes when clicked. In case of an exit without using the exit fullscreen button (e.g. typing ESC on the keyboard), the settings change back to the exited fullscreen mode. The body of the script contains all elements of the website: On top of everything, there is a red disclaimer in front of white background, warning the user that the website is just a coding project. Then, the headline with a blue background color is shown as well as the (exit) fullscreen button and a logo of the original goodnews website (accessed via the static folder in which I have downloaded the logo image). Then, for each article that was passed to the file the image, title, summary and date can be seen. Lastly, there is a footer with the same background as the heading, referencing goodnews and their website. If the viewer clicks on the hyperlinks, that person is guided to the referenced original/support website. Additionally, there is a static folder. It consists of the logo picture and a CSS file that sets the aesthetics. Besides the general settings like margin/padding/colors/height/width etc., it takes care of the button display as well as the slideshow set up. Furthermore, it wraps the image next to the title, summary and date for each article in a box at the center of the page. Lastly, it has some special configurations like e.g. fixed positions for the footer. At the bottom of the CSS, there are specifications in case of a smaller screen size – the title disappears and only the disclaimer is displayed along with some other small adjustments. Lastly, I have a python file called generate_index.py. The github website I use cannot load the content dynamically, meaning the articles can unfortunately not be updated on their own. Instead, scrape_news.py must be run in the terminal to update the database, then generate_index.py needs to be run. This file generates a static html which uses the templates/index.html as a template and fills in the latest 15 articles. The generated index.html can then serve as basis for the github website. With finally running app.py, the webpage can be visited.

